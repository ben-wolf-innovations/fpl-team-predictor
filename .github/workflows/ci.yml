name: CI Pipeline

on:
  push:
    branches:
      - feature/*
      - test
      - dev
      - prod
  pull_request:
    branches:
      - feature/*
      - test
      - dev
      - prod

jobs:
  test:
    runs-on: ubuntu-latest

    env:
      PYSPARK_SUBMIT_ARGS: >
        --packages io.delta:delta-core_2.12:2.4.0
        --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
        --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog
        pyspark-shell

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install Java
      run: |
        sudo apt-get update
        sudo apt-get install openjdk-11-jdk -y
        java -version

    - name: Set JAVA_HOME
      run: |
        echo "JAVA_HOME=$(dirname $(dirname $(readlink -f $(which java))))" >> $GITHUB_ENV
    - name: Install Python dependencies
      run: |
        pip install -r requirements.txt
        pip install pyspark chispa pytest

    - name: Run unit tests
      run: |
        export PYTHONPATH=$(pwd)/src
        python -m pytest tests/